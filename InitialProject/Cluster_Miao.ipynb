{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f97ff97c",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49a5063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "def load_data(name):\n",
    "    with h5py.File(f'{name}.h5', 'r') as f:\n",
    "        filename = name.split('/')[0]\n",
    "        return pandas.DataFrame(f[filename][:], dtype=np.float64)\n",
    "\n",
    "train = load_data('train')\n",
    "test  = load_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "685ba63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_variables = ['actualInteractionsPerCrossing', 'averageInteractionsPerCrossing', 'correctedActualMu', 'correctedAverageMu', 'correctedScaledActualMu', 'correctedScaledAverageMu', 'NvtxReco', 'p_nTracks', 'p_pt_track', 'p_eta', 'p_phi', 'p_charge', 'p_qOverP', 'p_z0', 'p_d0', 'p_sigmad0', 'p_d0Sig', 'p_EptRatio', 'p_dPOverP', 'p_z0theta', 'p_etaCluster', 'p_phiCluster', 'p_eCluster', 'p_rawEtaCluster', 'p_rawPhiCluster', 'p_rawECluster', 'p_eClusterLr0', 'p_eClusterLr1', 'p_eClusterLr2', 'p_eClusterLr3', 'p_etaClusterLr1', 'p_etaClusterLr2', 'p_phiClusterLr2', 'p_eAccCluster', 'p_f0Cluster', 'p_etaCalo', 'p_phiCalo', 'p_eTileGap3Cluster', 'p_cellIndexCluster', 'p_phiModCalo', 'p_etaModCalo', 'p_dPhiTH3', 'p_R12', 'p_fTG3', 'p_weta2', 'p_Reta', 'p_Rphi', 'p_Eratio', 'p_f1', 'p_f3', 'p_Rhad', 'p_Rhad1', 'p_deltaEta1', 'p_deltaPhiRescaled2', 'p_TRTPID', 'p_TRTTrackOccupancy', 'p_numberOfInnermostPixelHits', 'p_numberOfPixelHits', 'p_numberOfSCTHits', 'p_numberOfTRTHits', 'p_numberOfTRTXenonHits', 'p_chi2', 'p_ndof', 'p_SharedMuonTrack', 'p_E7x7_Lr2', 'p_E7x7_Lr3', 'p_E_Lr0_HiG', 'p_E_Lr0_LowG', 'p_E_Lr0_MedG', 'p_E_Lr1_HiG', 'p_E_Lr1_LowG', 'p_E_Lr1_MedG', 'p_E_Lr2_HiG', 'p_E_Lr2_LowG', 'p_E_Lr2_MedG', 'p_E_Lr3_HiG', 'p_E_Lr3_LowG', 'p_E_Lr3_MedG', 'p_ambiguityType', 'p_asy1', 'p_author', 'p_barys1', 'p_core57cellsEnergyCorrection', 'p_deltaEta0', 'p_deltaEta2', 'p_deltaEta3', 'p_deltaPhi0', 'p_deltaPhi1', 'p_deltaPhi2', 'p_deltaPhi3', 'p_deltaPhiFromLastMeasurement', 'p_deltaPhiRescaled0', 'p_deltaPhiRescaled1', 'p_deltaPhiRescaled3', 'p_e1152', 'p_e132', 'p_e235', 'p_e255', 'p_e2ts1', 'p_ecore', 'p_emins1', 'p_etconeCorrBitset', 'p_ethad', 'p_ethad1', 'p_f1core', 'p_f3core', 'p_maxEcell_energy', 'p_maxEcell_gain', 'p_maxEcell_time', 'p_maxEcell_x', 'p_maxEcell_y', 'p_maxEcell_z', 'p_nCells_Lr0_HiG', 'p_nCells_Lr0_LowG', 'p_nCells_Lr0_MedG', 'p_nCells_Lr1_HiG', 'p_nCells_Lr1_LowG', 'p_nCells_Lr1_MedG', 'p_nCells_Lr2_HiG', 'p_nCells_Lr2_LowG', 'p_nCells_Lr2_MedG', 'p_nCells_Lr3_HiG', 'p_nCells_Lr3_LowG', 'p_nCells_Lr3_MedG', 'p_pos', 'p_pos7', 'p_poscs1', 'p_poscs2', 'p_ptconeCorrBitset', 'p_ptconecoreTrackPtrCorrection', 'p_r33over37allcalo', 'p_topoetconeCorrBitset', 'p_topoetconecoreConeEnergyCorrection', 'p_topoetconecoreConeSCEnergyCorrection', 'p_weta1', 'p_widths1', 'p_widths2', 'p_wtots1', 'p_e233', 'p_e237', 'p_e277', 'p_e2tsts1', 'p_ehad1', 'p_emaxs1', 'p_fracs1', 'p_DeltaE', 'p_E3x5_Lr0', 'p_E3x5_Lr1', 'p_E3x5_Lr2', 'p_E3x5_Lr3', 'p_E5x7_Lr0', 'p_E5x7_Lr1', 'p_E5x7_Lr2', 'p_E5x7_Lr3', 'p_E7x11_Lr0', 'p_E7x11_Lr1', 'p_E7x11_Lr2', 'p_E7x11_Lr3', 'p_E7x7_Lr0', 'p_E7x7_Lr1' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9316a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[all_variables]\n",
    "y = train['Truth']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f36727",
   "metadata": {},
   "source": [
    "## K-Means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71f47dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "KMeans(\n",
    "    n_clusters=8,\n",
    "    init='k-means++',\n",
    "    n_init=10,\n",
    "    max_iter=300,\n",
    "    tol=0.0001,\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "    copy_x=True,\n",
    "    algorithm='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ae78b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmeans = KMeans(n_clusters=5)\n",
    "kmeans_model = Kmeans.fit(X)\n",
    "y_train = kmeans_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c708c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class KMeansInterp(KMeans):\n",
    "    def __init__(self, ordered_feature_names, feature_importance_method='wcss_min', **kwargs):\n",
    "        super(KMeansInterp, self).__init__(**kwargs)\n",
    "        self.feature_importance_method = feature_importance_method\n",
    "        self.ordered_feature_names = ordered_feature_names\n",
    "        \n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        super().fit(X=X, y=y, sample_weight=sample_weight)\n",
    "        \n",
    "        if not len(self.ordered_feature_names) == self.n_features_in_:\n",
    "            raise Exception(f\"Model is fitted on {self.n_features_in_} but ordered_feature_names = {len(self.ordered_feature_names)}\")\n",
    "        \n",
    "        if self.feature_importance_method == \"wcss_min\":\n",
    "            self.feature_importances_ = self.get_feature_imp_wcss_min()\n",
    "        elif self.feature_importance_method == \"unsup2sup\":\n",
    "            self.feature_importances_ = self.get_feature_imp_unsup2sup(X)\n",
    "        else: \n",
    "            raise Exception(f\" {self.feature_importance_method}\"+\\\n",
    "            \"is not available. Please choose from  ['wcss_min' , 'unsup2sup']\")\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def get_feature_imp_wcss_min(self):\n",
    "        labels = self.n_clusters\n",
    "        centroids = self.cluster_centers_\n",
    "        centroids = np.vectorize(lambda x: np.abs(x))(centroids)\n",
    "        sorted_centroid_features_idx = centroids.argsort(axis=1)[:,::-1]\n",
    "\n",
    "        cluster_feature_weights = {}\n",
    "        for label, centroid in zip(range(labels), sorted_centroid_features_idx):\n",
    "            ordered_cluster_feature_weights = centroids[label][sorted_centroid_features_idx[label]]\n",
    "            ordered_cluster_features = [self.ordered_feature_names[feature] for feature in centroid]\n",
    "            cluster_feature_weights[label] = list(zip(ordered_cluster_features, \n",
    "                                                      ordered_cluster_feature_weights))\n",
    "        \n",
    "        return cluster_feature_weights\n",
    "    \n",
    "    def get_feature_imp_unsup2sup(self, X):\n",
    "        try:\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "        except ImportError as IE:\n",
    "            print(IE.__class__.__name__ + \": \" + IE.message)\n",
    "            raise Exception(\"Please install scikit-learn. \" + \n",
    "                            \"'unsup2sup' method requires using a classifier\"+ \n",
    "                            \"and depends on 'sklearn.ensemble.RandomForestClassifier'\")\n",
    "        \n",
    "        cluster_feature_weights = {}\n",
    "        for label in range(self.n_clusters):\n",
    "            binary_enc = np.vectorize(lambda x: 1 if x == label else 0)(self.labels_)\n",
    "            clf = RandomForestClassifier()\n",
    "            clf.fit(X, binary_enc)\n",
    "\n",
    "            sorted_feature_weight_idxes = np.argsort(clf.feature_importances_)[::-1]\n",
    "            ordered_cluster_features = np.take_along_axis(\n",
    "                np.array(self.ordered_feature_names), \n",
    "                sorted_feature_weight_idxes, \n",
    "                axis=0)\n",
    "            ordered_cluster_feature_weights = np.take_along_axis(\n",
    "                np.array(clf.feature_importances_), \n",
    "                sorted_feature_weight_idxes, \n",
    "                axis=0)\n",
    "            cluster_feature_weights[label] = list(zip(ordered_cluster_features, \n",
    "                                                      ordered_cluster_feature_weights))\n",
    "        return cluster_feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "469aa37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kms = KMeansInterp(\n",
    "   n_clusters=5,\n",
    "   ordered_feature_names=X.columns.tolist(),\n",
    "   feature_importance_method='wcss_min', # or 'unsup2sup'\n",
    ").fit(X)\n",
    "\n",
    "# A dictionary where the key [0] is the cluster label, and [:10] will refer to the first 10 most important features\n",
    "feature_list = kms.feature_importances_[0][:5] # Features here are words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdd5732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_5 = []\n",
    "for i in range(len(feature_list)):\n",
    "    feature_5.append(feature_list[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d624a615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 0 ... 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Kmeans = KMeans(n_clusters=5)\n",
    "kmeans_model = Kmeans.fit(X[feature_5])\n",
    "y_cluster = kmeans_model.predict(test[feature_5])\n",
    "print(y_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5703d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cluster = pandas.DataFrame(y_cluster)\n",
    "y_cluster.columns=['cluster']\n",
    "\n",
    "y_cluster.to_csv('Clustering_MiaoShang_Kmeans.txt', index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7df71fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"Clustering_MiaoShang_Kmeans_VariableList.txt\",'w+')\n",
    "for i in range(len(feature_5)):\n",
    "    file.write(str(feature_5[i])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7465b82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appml",
   "language": "python",
   "name": "appml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
